#!/usr/bin/env python3
"""
ä¸­æ–‡è¯­éŸ³è¯†åˆ« - æ”¯æŒGoogle Speech APIå’ŒVoskç¦»çº¿è¯†åˆ«
é’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–ï¼Œæ”¯æŒé’‰é’‰OGGæ ¼å¼è‡ªåŠ¨è½¬æ¢
"""

import os
import json
import time
import tempfile
import subprocess
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import speech_recognition as sr

class RecognitionMode(Enum):
    """è¯†åˆ«æ¨¡å¼"""
    GOOGLE = "google"      # Google Speech API (åœ¨çº¿ï¼Œé«˜ç²¾åº¦)
    VOSK = "vosk"         # Voskç¦»çº¿è¯†åˆ« (æœ¬åœ°ï¼Œæ— éœ€ç½‘ç»œ)
    HYBRID = "hybrid"     # æ··åˆæ¨¡å¼ï¼Œè‡ªåŠ¨é€‰æ‹©

@dataclass
class RecognitionResult:
    """è¯†åˆ«ç»“æœ"""
    text: str
    confidence: float
    mode: RecognitionMode
    processing_time: float
    language: str = "zh-CN"
    error: Optional[str] = None

@dataclass
class ASRConfig:
    """ASRé…ç½®"""
    mode: RecognitionMode = RecognitionMode.HYBRID
    language: str = "zh-CN"
    proxy: Optional[str] = None
    vosk_model_path: Optional[str] = None
    google_api_key: Optional[str] = None
    auto_convert_formats: bool = True
    sample_rate: int = 16000
    channels: int = 1

class ChineseSpeechRecognizer:
    """ä¸­æ–‡è¯­éŸ³è¯†åˆ«å™¨"""
    
    def __init__(self, config: ASRConfig = None):
        """
        åˆå§‹åŒ–ä¸­æ–‡è¯­éŸ³è¯†åˆ«å™¨
        
        Args:
            config: ASRé…ç½®ï¼Œå¦‚æœä¸ºNoneä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config or ASRConfig()
        self.recognizer = sr.Recognizer()
        
        # åˆå§‹åŒ–Voskæ¨¡å‹ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        self.vosk_model = None
        if (self.config.mode in [RecognitionMode.VOSK, RecognitionMode.HYBRID] and 
            self.config.vosk_model_path):
            self._init_vosk_model()
        
        # è®¾ç½®ä»£ç†ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        if self.config.proxy:
            self._setup_proxy()
    
    def _init_vosk_model(self):
        """åˆå§‹åŒ–Voskæ¨¡å‹"""
        try:
            import vosk
            if os.path.exists(self.config.vosk_model_path):
                self.vosk_model = vosk.Model(self.config.vosk_model_path)
                print(f"âœ… Voskæ¨¡å‹åŠ è½½æˆåŠŸ: {self.config.vosk_model_path}")
            else:
                print(f"âš ï¸ Voskæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.config.vosk_model_path}")
        except ImportError:
            print("âš ï¸ Voskæœªå®‰è£…ï¼Œç¦»çº¿è¯†åˆ«ä¸å¯ç”¨")
            print("å®‰è£…: pip install vosk")
        except Exception as e:
            print(f"âŒ Voskæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def _setup_proxy(self):
        """è®¾ç½®ä»£ç†"""
        os.environ['HTTP_PROXY'] = self.config.proxy
        os.environ['HTTPS_PROXY'] = self.config.proxy
        print(f"âœ… ä»£ç†è®¾ç½®: {self.config.proxy}")
    
    def convert_audio_format(self, input_path: str, output_format: str = "wav") -> str:
        """
        è½¬æ¢éŸ³é¢‘æ ¼å¼
        
        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_format: è¾“å‡ºæ ¼å¼ (wav, flacç­‰)
            
        Returns:
            è½¬æ¢åçš„æ–‡ä»¶è·¯å¾„
        """
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢
        input_ext = Path(input_path).suffix.lower()
        if input_ext in ['.wav', '.flac'] and not self.config.auto_convert_formats:
            return input_path
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix=f'.{output_format}', delete=False) as tmp:
            output_path = tmp.name
        
        # ä½¿ç”¨ffmpegè½¬æ¢
        cmd = [
            'ffmpeg', '-i', input_path,
            '-ar', str(self.config.sample_rate),
            '-ac', str(self.config.channels),
            '-y', output_path
        ]
        
        try:
            subprocess.run(cmd, check=True, capture_output=True)
            print(f"âœ… éŸ³é¢‘æ ¼å¼è½¬æ¢: {input_path} -> {output_path}")
            return output_path
        except subprocess.CalledProcessError as e:
            print(f"âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥: {e}")
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè¿”å›åŸæ–‡ä»¶
            return input_path
        except FileNotFoundError:
            print("âŒ ffmpegæœªå®‰è£…ï¼Œæ— æ³•è½¬æ¢éŸ³é¢‘æ ¼å¼")
            return input_path
    
    def recognize_with_google(self, audio_path: str) -> RecognitionResult:
        """
        ä½¿ç”¨Google Speech APIè¯†åˆ«
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            è¯†åˆ«ç»“æœ
        """
        start_time = time.time()
        
        try:
            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            with sr.AudioFile(audio_path) as source:
                audio = self.recognizer.record(source)
            
            # è¯†åˆ«
            text = self.recognizer.recognize_google(
                audio,
                language=self.config.language,
                key=self.config.google_api_key
            )
            
            processing_time = time.time() - start_time
            
            return RecognitionResult(
                text=text,
                confidence=0.9,  # Google APIä¸è¿”å›ç½®ä¿¡åº¦
                mode=RecognitionMode.GOOGLE,
                processing_time=processing_time,
                language=self.config.language
            )
            
        except sr.UnknownValueError:
            processing_time = time.time() - start_time
            return RecognitionResult(
                text="",
                confidence=0.0,
                mode=RecognitionMode.GOOGLE,
                processing_time=processing_time,
                language=self.config.language,
                error="æ— æ³•è¯†åˆ«éŸ³é¢‘"
            )
        except sr.RequestError as e:
            processing_time = time.time() - start_time
            return RecognitionResult(
                text="",
                confidence=0.0,
                mode=RecognitionMode.GOOGLE,
                processing_time=processing_time,
                language=self.config.language,
                error=f"Google APIè¯·æ±‚å¤±è´¥: {e}"
            )
        except Exception as e:
            processing_time = time.time() - start_time
            return RecognitionResult(
                text="",
                confidence=0.0,
                mode=RecognitionMode.GOOGLE,
                processing_time=processing_time,
                language=self.config.language,
                error=f"è¯†åˆ«è¿‡ç¨‹é”™è¯¯: {e}"
            )
    
    def recognize_with_vosk(self, audio_path: str) -> RecognitionResult:
        """
        ä½¿ç”¨Voskç¦»çº¿è¯†åˆ«
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            è¯†åˆ«ç»“æœ
        """
        start_time = time.time()
        
        if not self.vosk_model:
            processing_time = time.time() - start_time
            return RecognitionResult(
                text="",
                confidence=0.0,
                mode=RecognitionMode.VOSK,
                processing_time=processing_time,
                language=self.config.language,
                error="Voskæ¨¡å‹æœªåŠ è½½"
            )
        
        try:
            import vosk
            import wave
            import json as json_lib
            
            # è¯»å–éŸ³é¢‘æ–‡ä»¶
            wf = wave.open(audio_path, "rb")
            
            # æ£€æŸ¥éŸ³é¢‘æ ¼å¼
            if wf.getnchannels() != self.config.channels:
                print(f"âš ï¸ éŸ³é¢‘å£°é“æ•°ä¸åŒ¹é…: {wf.getnchannels()} != {self.config.channels}")
            
            if wf.getframerate() != self.config.sample_rate:
                print(f"âš ï¸ é‡‡æ ·ç‡ä¸åŒ¹é…: {wf.getframerate()} != {self.config.sample_rate}")
            
            # åˆ›å»ºè¯†åˆ«å™¨
            rec = vosk.KaldiRecognizer(self.vosk_model, wf.getframerate())
            rec.SetWords(True)
            
            # è¯†åˆ«
            results = []
            while True:
                data = wf.readframes(4000)
                if len(data) == 0:
                    break
                if rec.AcceptWaveform(data):
                    result = json_lib.loads(rec.Result())
                    results.append(result.get("text", ""))
            
            # è·å–æœ€ç»ˆç»“æœ
            final_result = json_lib.loads(rec.FinalResult())
            final_text = final_result.get("text", "")
            
            # åˆå¹¶æ‰€æœ‰ç»“æœ
            all_text = " ".join(results + [final_text])
            all_text = all_text.strip()
            
            processing_time = time.time() - start_time
            
            return RecognitionResult(
                text=all_text,
                confidence=0.8,  # Voskç½®ä¿¡åº¦ä¼°ç®—
                mode=RecognitionMode.VOSK,
                processing_time=processing_time,
                language=self.config.language
            )
            
        except ImportError:
            processing_time = time.time() - start_time
            return RecognitionResult(
                text="",
                confidence=0.0,
                mode=RecognitionMode.VOSK,
                processing_time=processing_time,
                language=self.config.language,
                error="Voskæœªå®‰è£…"
            )
        except Exception as e:
            processing_time = time.time() - start_time
            return RecognitionResult(
                text="",
                confidence=0.0,
                mode=RecognitionMode.VOSK,
                processing_time=processing_time,
                language=self.config.language,
                error=f"Voskè¯†åˆ«å¤±è´¥: {e}"
            )
    
    def recognize_audio(self, audio_path: str) -> RecognitionResult:
        """
        è¯†åˆ«éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            è¯†åˆ«ç»“æœ
        """
        print(f"ğŸ” å¼€å§‹è¯†åˆ«: {audio_path}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(audio_path):
            return RecognitionResult(
                text="",
                confidence=0.0,
                mode=self.config.mode,
                processing_time=0.0,
                language=self.config.language,
                error=f"æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}"
            )
        
        # è‡ªåŠ¨è½¬æ¢æ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.config.auto_convert_formats:
            converted_path = self.convert_audio_format(audio_path, "wav")
            # å¦‚æœæ˜¯ä¸´æ—¶æ–‡ä»¶ï¼Œéœ€è¦åç»­æ¸…ç†
            is_temp = converted_path != audio_path
        else:
            converted_path = audio_path
            is_temp = False
        
        try:
            # æ ¹æ®æ¨¡å¼é€‰æ‹©è¯†åˆ«æ–¹æ³•
            if self.config.mode == RecognitionMode.GOOGLE:
                result = self.recognize_with_google(converted_path)
            elif self.config.mode == RecognitionMode.VOSK:
                result = self.recognize_with_vosk(converted_path)
            elif self.config.mode == RecognitionMode.HYBRID:
                # å°è¯•Googleï¼Œå¤±è´¥åˆ™ä½¿ç”¨Vosk
                google_result = self.recognize_with_google(converted_path)
                if google_result.error or not google_result.text:
                    print("Googleè¯†åˆ«å¤±è´¥ï¼Œå°è¯•Vosk...")
                    result = self.recognize_with_vosk(converted_path)
                    result.mode = RecognitionMode.HYBRID
                else:
                    result = google_result
                    result.mode = RecognitionMode.HYBRID
            else:
                result = RecognitionResult(
                    text="",
                    confidence=0.0,
                    mode=self.config.mode,
                    processing_time=0.0,
                    language=self.config.language,
                    error=f"æœªçŸ¥è¯†åˆ«æ¨¡å¼: {self.config.mode}"
                )
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if is_temp and os.path.exists(converted_path):
                os.remove(converted_path)
            
            # è¾“å‡ºç»“æœ
            if result.text:
                print(f"âœ… è¯†åˆ«æˆåŠŸ [{result.mode.value}]: {result.text}")
                print(f"   ç½®ä¿¡åº¦: {result.confidence:.2f}, è€—æ—¶: {result.processing_time:.2f}s")
            elif result.error:
                print(f"âŒ è¯†åˆ«å¤±è´¥: {result.error}")
            
            return result
            
        except Exception as e:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if is_temp and os.path.exists(converted_path):
                os.remove(converted_path)
            
            return RecognitionResult(
                text="",
                confidence=0.0,
                mode=self.config.mode,
                processing_time=time.time() - start_time,
                language=self.config.language,
                error=f"è¯†åˆ«è¿‡ç¨‹å¼‚å¸¸: {e}"
            )
    
    def recognize_dingtalk_voice(self, ogg_path: str) -> RecognitionResult:
        """
        ä¸“é—¨å¤„ç†é’‰é’‰è¯­éŸ³æ–‡ä»¶
        
        Args:
            ogg_path: é’‰é’‰OGGæ–‡ä»¶è·¯å¾„
            
        Returns:
            è¯†åˆ«ç»“æœ
        """
        print(f"ğŸ¯ å¤„ç†é’‰é’‰è¯­éŸ³: {ogg_path}")
        
        # é’‰é’‰è¯­éŸ³é€šå¸¸æ˜¯OGG/Opusæ ¼å¼ï¼Œéœ€è¦è½¬æ¢
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
            wav_path = tmp.name
        
        # è½¬æ¢OGGåˆ°WAV
        cmd = [
            'ffmpeg', '-i', ogg_path,
            '-ar', '16000',
            '-ac', '1',
            '-acodec', 'pcm_s16le',
            '-y', wav_path
        ]
        
        try:
            subprocess.run(cmd, check=True, capture_output=True)
            print(f"âœ… é’‰é’‰OGGè½¬æ¢å®Œæˆ: {ogg_path} -> {wav_path}")
            
            # è¯†åˆ«è½¬æ¢åçš„æ–‡ä»¶
            result = self.recognize_audio(wav_path)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.remove(wav_path)
            
            return result
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ é’‰é’‰OGGè½¬æ¢å¤±è´¥: {e}")
            # å°è¯•ç›´æ¥è¯†åˆ«ï¼ˆå¯èƒ½å¤±è´¥ï¼‰
            return self.recognize_audio(ogg_path)
        except Exception as e:
            print(f"âŒ é’‰é’‰è¯­éŸ³å¤„ç†å¼‚å¸¸: {e}")
            if os.path.exists(wav_path):
                os.remove(wav_path)
            return RecognitionResult(
                text="",
                confidence=0.0,
                mode=self.config.mode,
                processing_time=0.0,
                language=self.config.language,
                error=f"é’‰é’‰è¯­éŸ³å¤„ç†å¤±è´¥: {e}"
            )


# å‘½ä»¤è¡Œæ¥å£
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¸­æ–‡è¯­éŸ³è¯†åˆ«å·¥å…·')
    parser.add_argument('--audio', required=True, help='éŸ³é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--mode', choices=['google', 'vosk', 'hybrid'], 
                       default='hybrid', help='è¯†åˆ«æ¨¡å¼')
    parser.add_argument('--proxy', help='ä»£ç†æœåŠ¡å™¨')
    parser.add_argument('--vosk-model', help='Voskæ¨¡å‹è·¯å¾„')
    parser.add_argument('--google-key', help='Google API Key')
    parser.add_argument('--dingtalk', action='store_true', help='å¤„ç†é’‰é’‰OGGæ ¼å¼')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé…ç½®
    config = ASRConfig(
        mode=RecognitionMode(args.mode),
        proxy=args.proxy,
        vosk_model_path=args.vosk_model,
        google_api_key=args.google_key
    )
    
    # åˆ›å»ºè¯†åˆ«å™¨
    recognizer = ChineseSpeechRecognizer(config)
    
    # è¯†åˆ«
    if args.dingtalk:
        result = recognizer.recognize_dingtalk_voice(args.audio)
    else:
        result = recognizer.recognize_audio(args.audio)
    
    # è¾“å‡ºç»“æœ
    if result.text:
        print("\n" + "="*50)
        print("è¯†åˆ«ç»“æœ:")
        print(f"  æ–‡æœ¬: {result.text}")
        print(f"  æ¨¡å¼: {result.mode.value}")
        print(f"  ç½®ä¿¡åº¦: {result.confidence:.2f}")
        print(f"  è€—æ—¶: {result.processing_time:.2f}ç§’")
        print(f"  è¯­è¨€: {result.language}")
        print("="*50)
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        output_file = Path(args.audio).with_suffix('.txt')
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(result.text)
        print(f"âœ… ç»“æœå·²ä¿å­˜: {output_file}")
    else:
        print(f"âŒ è¯†åˆ«å¤±è´¥: {result.error}")